{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM5DoZ834U4vY4WSc4rBm61"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["###Step1. Define ImageDataset"],"metadata":{"id":"qsgjxcUDVKwV"}},{"cell_type":"code","source":["import glob #파일들의 리스트 추출 모듈\n","import random\n","import os\n","\n","from torch.utils.data import Dataset, DataLoader #\n","from PIL import Image\n","import torchvision.transforms as transforms #\n","import sys #\n","import torch.nn as nn #\n","import torch.nn.functional as F #\n","import torch #\n","\n","import os\n","import numpy as np\n","import math\n","import itertools\n","import datetime\n","import time\n","\n","from torchvision.utils import save_image, make_grid\n","from torchvision import datasets\n","from torch.autograd import Variable"],"metadata":{"id":"YqTQW0nJVK2t","executionInfo":{"status":"ok","timestamp":1685260196312,"user_tz":-540,"elapsed":9776,"user":{"displayName":"Eunae Kang","userId":"01300216816198274349"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["def to_rgb(image):\n","  rgb_image = Image.new(\"RGB\", image.size)\n","  rgb_image.paste(image)\n","  return rgb_image"],"metadata":{"id":"uF-XADGQVZI6","executionInfo":{"status":"ok","timestamp":1685260237576,"user_tz":-540,"elapsed":7,"user":{"displayName":"Eunae Kang","userId":"01300216816198274349"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["class ImageDataset(Dataset):\n","  def __init__(self, root, transforms_=None, unaligned=False, mode=\"train\"):\n","    self.transform = transforms.Compose(transforms_)\n","    self.unaligned = unaligned\n","    \n","    if mode==\"train\":\n","      self.files_A = sorted(glob.glob(os.path.join(root, \"trainA\") + \"/*.*\"))\n","      self.files_B = sorted(glob.glob(os.path.join(root, \"trainB\") + \"/*.*\"))\n","    else:\n","      self.files_A = sorted(glob.glob(os.path.join(root, \"testA\") + \"/*.*\"))\n","      self.files_B = sorted(glob.glob(os.path.join(root, \"testB\") + \"/*.*\"))\n","\n","  def __getitem__(self, index):\n","    image_A = Image.open(self.files_A[index % len(self.files_A)])\n","\n","    if self.unaligned: #학습할 쌍 무작위 선택 가능\n","      image_B = Image.open(self.files_B[random.randint(0, len(self.files_B) -1)])\n","    else:\n","      image_B = Image.open(self.files_B[index % len(self.files_B)])\n","\n","    if image_A.mode != \"RGB\":\n","      image_A = to_rgb(image_A)\n","    if image_B.mode != \"RGB\":\n","      image_B = to_rgb(image_B)   \n","\n","    item_A = self.transform(image_A) #transform 함수를 통해 torch의 tensor 형태로 변환\n","    item_B = self.transform(image_B)\n","\n","    return {\"A\": item_A, \"B\": item_B}\n","\n","  def __len__(self):\n","      return max(len(self.files_A), len(self.files_B))   "],"metadata":{"id":"k9XScTRQVnZu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step2. Define the transform function"],"metadata":{"id":"EyqZR7R3ep2_"}},{"cell_type":"code","source":["transforms_ = [\n","    transforms.Resize(int(img_height*1.12), Image.BICUBIC),   #1. PIL 이미지를 resize, 보간 방식은 BICUBIC\n","    transforms.RandomCrop((img_height, img_width)),           #PIL 이미지를 무작위로 crop\n","    transforms.RandomHorizontalFlip(),                        #PIL 이미지를 무작위로 좌우 변환\n","    transforms.ToTensor(),                                   #2. to_tensor: 0~1 사이의 Tensor 자료형으로 변환\n","    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5,)), #3. normalize: RGB 채널별로 평균 0.5, 표준편차 0.5로 정규화\n","]"],"metadata":{"id":"tqTCp7goeLzf"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["###Step3. Define the DataLoader"],"metadata":{"id":"MayKA16bgXqn"}},{"cell_type":"code","source":["#Training data loader\n","dataloader= DataLoader(\n","    ImageDataset(\"./dataset/%s\" % dataset_name, transforms_=transforms_, unaligned=True),\n","    batch_size=batch_size,\n","    shuffle=True,\n","    num_workers=n_cpu,\n",")\n","\n","#Test data loader\n","val_dataloader= DataLoader(\n","    ImageDataset(\"./dataset/%s\" % dataset_name, transforms_=transforms_, unaligned=True, mode=\"test\"),\n","    batch_size=5,\n","    shuffle=True,\n","    num_workers=1,\n",")"],"metadata":{"id":"7-q2al9gga61"},"execution_count":null,"outputs":[]}]}