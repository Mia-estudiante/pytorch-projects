{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPZk1xoAF1R2xU6RdRNQXw6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["### Step1. Ready for Tranfer Learning"],"metadata":{"id":"WXoeeYG6C82R"}},{"cell_type":"code","source":["import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader"],"metadata":{"id":"ZImUE0edV471"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_transforms = {\n","    'train': transforms.Compose([\n","        transforms.Resize([64,64]),\n","        transforms.RandomHorizontalFlip(),\n","        transforms.RandomVerticalFlip(),\n","        transforms.RandomCrop(52), #이미지 일부를 랜덤하게 잘라내어 52*52 사이즈로 변경\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406], #입력 데이터 정규화(평균, 표준편차)\n","                             [0.229, 0.224, 0.225]) #데이터 정규화는 모델을 최적화하며 Local Minimum에 빠지는 것 방지\n","    ]),\n","    'val': transforms.Compose([\n","        transforms.Resize([64,64]),\n","        transforms.RandomCrop(52),\n","        transforms.ToTensor(),\n","        transforms.Normalize([0.485, 0.456, 0.406],\n","                             [0.229, 0.224, 0.225])\n","    ])\n","}"],"metadata":{"id":"F_xHszxnVuar","executionInfo":{"status":"ok","timestamp":1684203323982,"user_tz":-540,"elapsed":14,"user":{"displayName":"Eunae Kang","userId":"01300216816198274349"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["data_dir = './splitted'\n","\n","#datasets 준비 + transform\n","image_datasets = {x: ImageFolder(root=os.path.join(data_dir, x), transform=data_transforms[x])\n","                  for x in ['train', 'val']}\n","                  \n","#미니 배치로 분리하는 역할\n","dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x], \n","                  batch_size=BATCH_SIZE, shuffle=True, num_workers=4) for x in ['train', 'val']}\n","dataset_sizes = {x: len(image_datasets[x]) for x in ['train', 'val']}\n","\n","class_names = image_datasets['train'].classes"],"metadata":{"id":"jH3rwhxSVxbt"},"execution_count":null,"outputs":[]}]}