{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMN75EmdDvUAtPVOhwVHNSh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"f3wL--yJEJBI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1684061674487,"user_tz":-540,"elapsed":25110,"user":{"displayName":"Eunae Kang","userId":"01300216816198274349"}},"outputId":"f6af4152-e3c4-4c6c-b404-d69e6531055a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["cd /content/drive/MyDrive/Mia-Github/Colabs/git-pytorch-projects/pytorch-projects"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zjv2YNS25VYK","executionInfo":{"status":"ok","timestamp":1684061768665,"user_tz":-540,"elapsed":915,"user":{"displayName":"Eunae Kang","userId":"01300216816198274349"}},"outputId":"7b120f0a-0f21-4e6f-d4b2-5e0ab4ad2d16"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Mia-Github/Colabs/git-pytorch-projects/pytorch-projects\n"]}]},{"cell_type":"markdown","source":["### Step1. Data 분할 위한 디렉토리 생성 - Train / Validation / Test\n","\n"],"metadata":{"id":"MPYCD1_-582R"}},{"cell_type":"code","source":["import os\n","import shutil"],"metadata":{"id":"Q5WHqmES5g4q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#1. 원본 데이터(with 클래스별 하위 디렉토리 포함)가 있는 곳\n","original_dataset_dir = './dataset'\n","class_list = os.listdir(original_dataset_dir)"],"metadata":{"id":"kCqiW3eg7AsC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#2. train, val, test 폴더 포함할 디렉토리 생성\n","base_dir = './splitted'\n","os.mkdir(base_dir)"],"metadata":{"id":"RfIOb6Y978Ab"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#3. 하위 train, val, test 폴더 생성\n","train_dir = os.path.join(base_dir, 'train') #./splitted/train\n","os.mkdir(train_dir)\n","\n","val_dir = os.path.join(base_dir, 'val') #./splitted/val\n","os.mkdir(val_dir)\n","\n","test_dir = os.path.join(base_dir, 'test') #./splitted/test\n","os.mkdir(test_dir)"],"metadata":{"id":"bHKO3caj75MX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#3. 하위 train, val, test 폴더 내 클래스별 폴더 생성\n","for clss in class_list:\n","  os.mkdir(os.path.join(train_dir, clss))\n","  os.mkdir(os.path.join(val_dir, clss))\n","  os.mkdir(os.path.join(test_dir, clss))"],"metadata":{"id":"VPGLXzd28oIh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step2. 데이터 분할과 클래스별 데이터 수 확인"],"metadata":{"id":"PpAuCf6Y-82t"}},{"cell_type":"code","source":["import math"],"metadata":{"id":"9ygFgxAx_Gdu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["for clss in class_list:\n","  path = os.path.join(original_dataset_dir, clss) #./dataset/class명\n","  fnames = os.listdir(path) #path 내 파일들\n","\n","  train_size = math.floor(len(fnames)*0.6)\n","  val_size = math.floor(len(fnames)*0.2)  \n","  test_size = math.floor(len(fnames)*0.2)\n","\n","  train_fnames = fnames[:train_size]\n","  for f in train_fnames:\n","    src = os.path.join(path, f) #./dataset/class명/파일명\n","    dst = os.path.join(os.path.join(train_dir, clss), f) #./splitted/train/class명/파일명\n","    shutil.copyfile(src, dst)\n","\n","  val_fnames = fnames[train_size:train_size+val_size]\n","  for f in val_fnames:\n","    src = os.path.join(path, f) #./dataset/class명/파일명\n","    dst = os.path.join(os.path.join(val_dir, clss), f) #./splitted/val/class명/파일명\n","    shutil.copyfile(src, dst) \n","\n","  test_fnames = fnames[train_size+val_size:]\n","  for f in test_fnames:\n","    src = os.path.join(path, f) #./dataset/class명/파일명\n","    dst = os.path.join(os.path.join(test_dir, clss), f) #./splitted/test/class명/파일명\n","    shutil.copyfile(src, dst) "],"metadata":{"id":"OGoi9KeC_H4j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step3. 데이터셋 준비 완료, Dataloader 생성"],"metadata":{"id":"Gf6uEAxsCcTF"}},{"cell_type":"code","source":["import torch\n","import torchvision.transforms as transforms\n","from torchvision.datasets import ImageFolder\n","from torch.utils.data import DataLoader"],"metadata":{"id":"AoezoyGaCksf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["USE_CUDA = torch.cuda.is_available()\n","DEVICE = torch.device('cuda' if USE_CUDA else 'cpu')"],"metadata":{"id":"7AXC6UEnClyP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["BATCH_SIZE = 256\n","EPOCH = 30"],"metadata":{"id":"y7dvFkWGC1ow"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#transforms.Compose()\n","#이미지 데이터 전처리 / 텐서 형태로 변환\n","transform_base = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])"],"metadata":{"id":"tA-M_KujDBBb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#ImageFolder\n","#데이터셋을 불러오는 메소드\n","#하나의 클래스 = 하나의 폴더일 경우 사용\n","train_dataset = ImageFolder(root='./splitted/train', transform=transform_base)\n","val_dataset = ImageFolder(root='./splitted/val', transform=transform_base)"],"metadata":{"id":"C_o11GsLDLdq"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#DataLoader\n","#불러온 이미지 데이터를 주어진 조건에 따라 미니 배치 단위로 분리\n","#shuffle을 이용해 데이터의 순서가 섞여 모델이 학습시, label 정보 순서를 기억하는 것 방지\n","train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n","val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)"],"metadata":{"id":"eKHK-fbODXGA"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Step4. 베이스라인 모델 설계"],"metadata":{"id":"QfA1wv8sf2Pr"}},{"cell_type":"code","source":["import torch.nn as nn\n","import torch.nn.Function as F\n","import torch.optim as optim"],"metadata":{"id":"QuhyiuzFf6bd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#nn.Module: 딥러닝 모델과 관련된 기본적인 함수를 포함하는 클래스\n","class Net(nn.Module):\n","    \n","    #딥러닝 모델에서 사용할 모든 Layer 정의\n","    def __init__(self):\n","        super(Net, self).__init__()\n","\n","        self.conv1 = nn.Conv2d(3, 32, 3, padding=1) #입력 채널수, 출력 채널수, 커널 크기\n","        self.pool = nn.MaxPool2d(2, 2) #커널 크기, stride\n","        self.conv2 = nn.Conv2d(32, 64, 3, padding=1) \n","        self.conv3 = nn.Conv2d(64, 64, 3, padding=1) \n","\n","        self.fc1 = nn.Linear(4096, 512) #입력 채널수, 출력 채널수\n","        self.fc2 = nn.Linear(512, 33) #33은 출력 채널수로 부류 클래스 수와 동일\n","\n","    def forward(self, x):\n","        x = conv1(x)\n","        x = F.relu(x)\n","        x = pool(x)\n","        x = F.dropout(x, p=0.25, training=self.training) # 25% 노드 dropout, training은 학습 모드 적용 의미\n","\n","        x = self.conv2(x)\n","        x = F.relu(x)\n","        x = F.dropout(x, p=0.25, training=self.training)\n","\n","        x = self.conv3(x)\n","        x = F.relu(x)\n","        x = self.pool(x)\n","        x = F.dropout(x, p=0.25, training=self.trainig)\n","\n","        x = x.view(-1, 4096) #Flatten\n","        x = self.fc1(x)\n","        x = F.relu(x)\n","        x = F.dropout(x, p=0.5, training=self.training) #training은 학습 모드와 검증 모드를 다르게 적용하기 위해 존재\n","                                                        #즉, 학습 과정에서는 일부 노드를 랜덤 제외하지만\n","                                                        #    평가 과정에서는 모든 노드 사용하기에\n","        x = self.fc2(x)\n","\n","        return F.log_softmax(x, dim=1) #데이터가 각 클래스에 속할 확률을 output으로 추출\n","\n","model_base = Net().to(DEVICE) #to(DEVICE)를 통해 모델을 현재 사용중인 장비에 할당\n","optimizer = optim.Adam(model_base.parameters(), lr=0.001)"],"metadata":{"id":"yKPex-nOf_3M"},"execution_count":null,"outputs":[]}]}